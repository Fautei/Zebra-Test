{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403ea010",
   "metadata": {},
   "source": [
    "# Установка зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbe23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "! pip install opencv-python wandb ultralytics \n",
    "\n",
    "# Я использую weights and biases для мониторинга экспериментов\n",
    "! yolo settings wandb=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118abcff",
   "metadata": {},
   "source": [
    "# Извлечение изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9837ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "train = [\"1.MOV\", \"2_1.MOV\", \"4.MOV\"]\n",
    "val = [\"3_1.MOV\"]\n",
    "test = [\"3_2.MOV\"]\n",
    "\n",
    "path_to_videos = Path(\"data/videos_raw\")\n",
    "dataset_path = Path(\"data/dataset\")\n",
    "\n",
    "with open(dataset_path/\"data.yaml\", 'r') as f:\n",
    "    dataset_meta = yaml.safe_load(f)\n",
    "    # CVAT все еще не может нормально экспортировать yolo формат(\n",
    "with open(dataset_path/\"data.yaml\", 'w') as f:\n",
    "    dataset_meta[\"train\"] = \"images/Train\"\n",
    "    dataset_meta[\"val\"] = \"images/Validation\"\n",
    "    dataset_meta[\"test\"] = \"images/Test\"\n",
    "    dataset_meta[\"path\"] = \"data/dataset\"\n",
    "    yaml.safe_dump(dataset_meta, f)\n",
    "\n",
    "classes = dataset_meta[\"names\"]\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6bf2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_yolo_labels(label_path):\n",
    "    labels = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue  # пропускаем неправильные строки\n",
    "            class_id = int(parts[0])\n",
    "            x_center = float(parts[1])\n",
    "            y_center = float(parts[2])\n",
    "            width = float(parts[3])\n",
    "            height = float(parts[4])\n",
    "            labels.append({\n",
    "                'class_id': class_id,\n",
    "                'x_center': x_center,\n",
    "                'y_center': y_center,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "    return labels\n",
    "\n",
    "def save_yolo_labels(label_path, labels):\n",
    "    with open(label_path, 'w') as f:\n",
    "        for label in labels:\n",
    "            line = f\"{label['class_id']} {label['x_center']:.6f} {label['y_center']:.6f} {label['width']:.6f} {label['height']:.6f}\\n\"\n",
    "            f.write(line)\n",
    "\n",
    "def flip_frame_and_labels(frame, labels, horizontal=False, vertical=False):\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    # Отразим изображение\n",
    "    if horizontal and vertical:\n",
    "        frame = cv2.flip(frame, -1)\n",
    "    elif horizontal:\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    elif vertical:\n",
    "        frame = cv2.flip(frame, 0)\n",
    "\n",
    "    # Отразим лейблы\n",
    "    flipped_labels = []\n",
    "    for label in labels:\n",
    "        x = label['x_center']\n",
    "        y = label['y_center']\n",
    "\n",
    "        if horizontal:\n",
    "            x = 1.0 - x\n",
    "        if vertical:\n",
    "            y = 1.0 - y\n",
    "\n",
    "        flipped_labels.append({\n",
    "            'class_id': label['class_id'],\n",
    "            'x_center': x,\n",
    "            'y_center': y,\n",
    "            'width': label['width'],\n",
    "            'height': label['height']\n",
    "        })\n",
    "\n",
    "    return frame, flipped_labels\n",
    "\n",
    "def draw_boxes(img, labels, class_names):\n",
    "    img_h, img_w = img.shape[:2]\n",
    "    def get_color(class_id):\n",
    "        return (30*class_id % 255, 70*class_id % 255, abs(255 - 50 * class_id) % 255)\n",
    "\n",
    "    for label in labels:\n",
    "        # Преобразуем нормализованные координаты в пиксели\n",
    "        x_center = label['x_center'] * img_w\n",
    "        y_center = label['y_center'] * img_h\n",
    "        width = label['width'] * img_w\n",
    "        height = label['height'] * img_h\n",
    "\n",
    "        # Координаты бокса (левая верхняя и правая нижняя точки)\n",
    "        x1 = int(x_center - width / 2)\n",
    "        y1 = int(y_center - height / 2)\n",
    "        x2 = int(x_center + width / 2)\n",
    "        y2 = int(y_center + height / 2)\n",
    "        class_id = label['class_id']\n",
    "        color = get_color(class_id)\n",
    "        # Рисуем прямоугольник\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        # Подпись с названием класса\n",
    "        label_text = class_names[class_id] if class_names else str(class_id)\n",
    "        cv2.putText(img, label_text, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "for name, videos in tqdm([(\"Train\", train), (\"Validation\", val), (\"Test\", test)]):\n",
    "    frame_counter = 0\n",
    "    for video in videos:\n",
    "        cap = cv2.VideoCapture(path_to_videos / video)\n",
    "        while True:\n",
    "            res, frame = cap.read()\n",
    "            if not res:\n",
    "                break\n",
    "            \n",
    "            # уменьшаем размер в 16 раз, 4к в данный момент нам не нужно\n",
    "            frame = cv2.resize(frame, None,fx=0.25, fy=0.25) \n",
    "            #Opencv зачем то повернуло видео на 90 градусов, разворачиваем обратно\n",
    "            #print(frame.shape)\n",
    "            frame = frame.transpose(1,0,2)[:,::-1,:].copy()\n",
    "\n",
    "            label_path = dataset_path / \"labels\" / name / f\"frame_{frame_counter:06d}.txt\"\n",
    "            labels = read_yolo_labels(label_path)\n",
    "\n",
    "            # Т.к у нас очень сильный data leakage перевернем изображения из тестового набора вертикально,\n",
    "            # чтобы иммитировать другой сценарий и убедится что модель не тупо заучила все возможные положения меток\n",
    "            if name in (\"Test\"):\n",
    "                frame, labels = flip_frame_and_labels(frame, labels, vertical=True)\n",
    "                save_yolo_labels(label_path, labels)\n",
    "\n",
    "            # используем каждый 5 кадр для ускорения экспериментов\n",
    "            if frame_counter % 5 == 0:\n",
    "                if not os.path.exists(dataset_path / \"images\" / name):\n",
    "                    os.makedirs(dataset_path / \"images\" / name)\n",
    "\n",
    "            cv2.imwrite(dataset_path / \"images\" / name / f\"frame_{frame_counter:06d}.png\", frame)\n",
    "\n",
    "            #Сразу отображаем экспортированные аннотации, что бы убедиться в корректности данных\n",
    "            draw_boxes(frame, labels, classes)\n",
    "\n",
    "            frame_counter +=1\n",
    "\n",
    "            cv2.imshow(\"frame\", frame)\n",
    "            key = cv2.waitKey(1)\n",
    "            if ord('q') == key:\n",
    "                break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c373c",
   "metadata": {},
   "source": [
    "# Baseline тренировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11n.pt\") #nano модель что бы не переобучить\n",
    "\n",
    "# Запустим тренировку на 50 эпох что бы посмотреть как быстро модель переобучится\n",
    "model.train(\n",
    "    data=\"data/dataset/data.yaml\",  \n",
    "    epochs=50,                 \n",
    "    imgsz=640,                  \n",
    "    batch=32,               \n",
    "    project=\"Zebra-test\",      \n",
    "    name=\"experiments/baseline\",     \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9197a896",
   "metadata": {},
   "source": [
    "### Проверяем на отложенной выборке (видео перевернуто, для имитации другого сценария)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab55c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"Zebra-test/experiments/baseline/weights/best.pt\")\n",
    "\n",
    "metrics = model.val(data=\"data/dataset/data.yaml\", split=\"test\")\n",
    "print(metrics.box.map50) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f46666f",
   "metadata": {},
   "source": [
    "### Визуализируем предсказания baseline на тестовом видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a9336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "video_path = \"data/videos_raw/3_2.MOV\"\n",
    "output_path = \"results/baseline.mp4\"\n",
    "\n",
    "def save_video(model, video_path, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # В обратном порядке, что бы перевернуть видео\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = frame.transpose(1,0,2)[:,::-1,:].copy()\n",
    "\n",
    "        results = model.predict(source=frame, stream=False, show=False, conf=0.25)[0]\n",
    "        annotated_frame = results.plot()\n",
    "        out.write(annotated_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"✅ Saved: {output_path}\")\n",
    "\n",
    "save_video(model, video_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aefa255",
   "metadata": {},
   "source": [
    "# Добавляем аугментаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все еще nano модель\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Так же я позволил себе явно указать используемый оптимайзер, и изменить learning rate\n",
    "# но забыл указать что это сделал в отчете\n",
    "model.train(\n",
    "    data=\"data/dataset/data.yaml\",  \n",
    "    epochs=50,                 \n",
    "    imgsz=640,                  \n",
    "    batch=32,\n",
    "    optimizer = \"AdamW\", \n",
    "    lr0 = 3e-4, #Karpatov magic constant for AdamW             \n",
    "    project=\"Zebra-test\",      \n",
    "    name=\"experiments/augs_tuned\", \n",
    "    warmup_epochs=3,\n",
    "    translate = 0.1,\n",
    "    mosaic= 0.3,\n",
    "    #close_mosaic= 3,\n",
    "    mixup= 0.2,\n",
    "    # Не используем отражение по вертикали, потому что это будет читерство в данном контексте\n",
    "    #flipud= 0.5, \n",
    "    fliplr= 0.5,\n",
    "    scale= 0.5,\n",
    "    copy_paste = 0.4,\n",
    "    erasing = 0.2,\n",
    "    shear = 15,\n",
    "    degrees= 90, \n",
    "    hsv_h = 0.1,\n",
    "    hsv_s = 0.1,\n",
    "    hsv_v = 0.5,\n",
    "    cos_lr = True, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f141c",
   "metadata": {},
   "source": [
    "### Проверяем на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eada76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"Zebra-test/experiments/augs_tuned/weights/best.pt\")\n",
    "\n",
    "metrics = model.val(data=\"data/dataset/data.yaml\", split=\"test\")\n",
    "print(metrics.box.map50) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa5220",
   "metadata": {},
   "source": [
    "### Сохраняем предсказания улучшенной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db3350",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_video(model, video_path, \"results/tuned.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf29118",
   "metadata": {},
   "source": [
    "# Бонус - как получить наивысшие метрики если вы вообще ничего не понимаете в ML\n",
    "### Создаем новый датасет из вообще всех размеченных изображений, 20% перекладываем в валидацию, 20% в тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "original_dataset = Path(\"data/dataset\")  # Путь к оригинальному датасету\n",
    "silly_dataset = Path(\"data/silly_dataset\")  # Куда складываем новый датасет\n",
    "silly_dataset.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Собираем все изображения\n",
    "all_images = list(original_dataset.glob(\"images/*/*.png\")) + \\\n",
    "             list(original_dataset.glob(\"images/*/*.jpg\")) + \\\n",
    "             list(original_dataset.glob(\"images/*/*.jpeg\"))\n",
    "\n",
    "random.shuffle(all_images)\n",
    "\n",
    "# Разделение\n",
    "n = len(all_images)\n",
    "val_split = int(n * 0.2)\n",
    "test_split = int(n * 0.2)\n",
    "\n",
    "val_images = all_images[:val_split]\n",
    "test_images = all_images[val_split:val_split + test_split]\n",
    "train_images = all_images[val_split + test_split:]\n",
    "\n",
    "splits = {\n",
    "    \"Train\": train_images,\n",
    "    \"Validation\": val_images,\n",
    "    \"Test\": test_images\n",
    "}\n",
    "\n",
    "# Копируем изображения и соответствующие метки\n",
    "for split_name, image_list in splits.items():\n",
    "    image_dir = silly_dataset / \"images\" / split_name\n",
    "    label_dir = silly_dataset / \"labels\" / split_name\n",
    "    image_dir.mkdir(parents=True, exist_ok=True)\n",
    "    label_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for img_path in image_list:\n",
    "        # Копируем изображение\n",
    "        new_img_path = image_dir / img_path.name\n",
    "        shutil.copy(img_path, new_img_path)\n",
    "\n",
    "        # Соответствующий .txt файл\n",
    "        label_path = original_dataset / \"labels\" / img_path.parent.name / (img_path.stem + \".txt\")\n",
    "        if label_path.exists():\n",
    "            shutil.copy(label_path, label_dir / label_path.name)\n",
    "\n",
    "# Записываем новый data.yaml\n",
    "yaml_content = f\"\"\"path: {silly_dataset.resolve()}\n",
    "train: images/Train\n",
    "val: images/Validation\n",
    "test: images/Test\n",
    "\n",
    "names:\n",
    "  0: dish\n",
    "  1: drink\n",
    "  2: silverware\n",
    "  3: garbage/other\n",
    "\"\"\"\n",
    "\n",
    "with open(silly_dataset / \"data.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"✅ Silly dataset создан в:\", silly_dataset.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0486f094",
   "metadata": {},
   "source": [
    "### Берем модель побольше, потому что больше - лучше)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a3631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11l.pt\")\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data/silly_dataset/data.yaml\",  \n",
    "    epochs=50,                 \n",
    "    imgsz=640,                  \n",
    "    batch=32,\n",
    "    optimizer = \"AdamW\",\n",
    "    lr0 = 3e-4, #Karpatov magic constant for AdamW             \n",
    "    project=\"Zebra-test\",      \n",
    "    name=\"experiments/silly\", \n",
    "    warmup_epochs=3,\n",
    "    translate = 0.1,\n",
    "    mosaic= 0.3,\n",
    "    #close_mosaic= 3,\n",
    "    mixup= 0.2,\n",
    "    #flipud= 0.5, # Не используем отражение по вертикали, потому что это будет читерство в данном контексте\n",
    "    fliplr= 0.5,\n",
    "    scale= 0.5,\n",
    "    copy_paste = 0.4,\n",
    "    erasing = 0.2,\n",
    "    shear = 15,\n",
    "    degrees= 90, \n",
    "    hsv_h = 0.1,\n",
    "    hsv_s = 0.1,\n",
    "    hsv_v = 0.5,\n",
    "    cos_lr = True, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16af1a78",
   "metadata": {},
   "source": [
    "### Тестируем на отложенной выборке, которая пришла из того же распределения что и тренировочная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f5d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"Zebra-test/experiments/silly/weights/best.pt\")\n",
    "\n",
    "metrics = model.val(data=\"data/dataset/data.yaml\", split=\"test\")\n",
    "print(metrics.box.map50) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8140a14",
   "metadata": {},
   "source": [
    "### Наслаждаемся качеством ~~пере~~обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bafe4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_video(model, video_path, \"results/overfitted.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
